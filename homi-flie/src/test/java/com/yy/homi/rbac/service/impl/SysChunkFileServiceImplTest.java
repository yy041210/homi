package com.yy.homi.rbac.service.impl;

import com.yy.homi.common.domain.entity.R;
import com.yy.homi.file.domain.entity.SysUploadTask;
import com.yy.homi.file.domain.dto.request.UploadChunkReqDTO;
import com.yy.homi.file.mapper.SysUploadTaskMapper;
import com.yy.homi.file.service.SysChunkFileService;
import com.yy.homi.common.utils.FileUtils;
import lombok.extern.slf4j.Slf4j;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.mock.web.MockMultipartFile;

import java.io.*;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;

@Slf4j
@SpringBootTest
public class SysChunkFileServiceImplTest {

    @Autowired
    private SysChunkFileService sysChunkFileService;
    @Autowired
    private SysUploadTaskMapper sysUploadTaskMapper;

    // æµ‹è¯•é…ç½®æ–‡ä»¶è·¯å¾„
    private final String filePath = "D:\\BaiduNetdiskDownload\\license plate recognition.zip";
    private final String bucketName = "homi-file";
    private final Long chunkSize = 1024 * 1024 * 20L;  //åˆ†å—å¤§å°
    private final Long taskId = 2013429648273022979L;

    @Test
    @DisplayName("é«˜å¹¶å‘ä¸Šä¼ æµ‹è¯•ï¼šæ¨¡æ‹Ÿå¤šçº¿ç¨‹åŒæ—¶ä¸Šä¼ åŒä¸€ä¸ªåˆ†ç‰‡")
    public void testConcurrentUpload() throws Exception {
        int threadCount = 50; // 50ä¸ªè¯·æ±‚åŒæ—¶æŠ¢ä¼ ç¬¬1ç‰‡
        ExecutorService executor = Executors.newFixedThreadPool(threadCount);
        CountDownLatch latch = new CountDownLatch(1);

        // 1. ä»å¤§æ–‡ä»¶ä¸­åˆ‡å‡ºç¬¬ä¸€ç‰‡ä½œä¸ºç´ æ
        byte[] firstChunkData = getChunkDataFromFile(filePath, 0, chunkSize);
        String chunkHash = FileUtils.getSha256(new ByteArrayInputStream(firstChunkData));

        List<CompletableFuture<R>> futures = new ArrayList<>();

        for (int i = 0; i < threadCount; i++) {
            futures.add(CompletableFuture.supplyAsync(() -> {
                try {
                    latch.await(); // ç­‰å¾…å‘ä»¤æªå“
                    MockMultipartFile file = new MockMultipartFile("chunkFile", "part_1", "application/octet-stream", firstChunkData);

                    UploadChunkReqDTO dto = new UploadChunkReqDTO();
                    dto.setTaskId(taskId);
                    dto.setChunkIndex(1); // å›ºå®šä¸Šä¼ ç¬¬1ç‰‡
                    dto.setChunkFile(file);
                    dto.setChunkHash(chunkHash);
                    dto.setBucketName(bucketName);

                    return sysChunkFileService.uploadChunk(dto);
                } catch (Exception e) {
                    return R.fail(e.getMessage());
                }
            }, executor));
        }

        System.out.println("ğŸš€ å‡†å¤‡å°±ç»ªï¼Œ50ä¸ªè¯·æ±‚å¼€å§‹å†²æ’ uploadChunk æ¥å£...");
        latch.countDown();
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();

        // 2. éªŒè¯ç»“æœ
        int successCount = 0;
        int failCount = 0;
        for (CompletableFuture<R> f : futures) {
            R r = f.join();
            if (r.getCode() == 200) {
                successCount++;
            } else if (r.getCode() == 500) {
                failCount++;
                log.error("å¼‚å¸¸ä¿¡æ¯ï¼š{}", r.getMsg());
            }
        }
        System.out.println("âœ… ç»“æœï¼šå¹¶å‘è¯·æ±‚50æ¬¡ï¼Œr.okæ¬¡æ•°ï¼š" + successCount);
    }


    @Test
    @DisplayName("é«˜å¹¶å‘ä¸Šä¼ æµ‹è¯•ï¼šæ¨¡æ‹Ÿå¤šçº¿ç¨‹åŒæ—¶ä¸Šä¼ åŒä¸€ä¸ªå¤§æ–‡ä»¶")
    public void testConcurrentUploadBigFile() throws Exception {
        int threadCount = 10; // 40ä¸ªè¯·æ±‚åŒæ—¶æŠ¢ä¼ ä¸€ä¸ªåˆ†ç‰‡
        ExecutorService executor = Executors.newFixedThreadPool(threadCount);
        CountDownLatch latch = new CountDownLatch(1);

        //1.å¤§æ–‡ä»¶éœ€è¦åˆ†æˆçš„ç‰‡æ•°
        SysUploadTask sysUploadTask = sysUploadTaskMapper.selectById(taskId);
        Integer totalChunks = sysUploadTask.getTotalChunks();

        for (int i = 0; i < totalChunks; i++) {
            System.out.println("=======================  åˆ†ç‰‡" + (i+1) + "==========================");
            byte[] firstChunkData = getChunkDataFromFile(filePath, i, chunkSize);
            String chunkHash = FileUtils.getSha256(new ByteArrayInputStream(firstChunkData));
            List<CompletableFuture<R>> futures = new ArrayList<>();

            for (int j = 0; j < threadCount; j++) {
                int finalI = i+1;
                futures.add(CompletableFuture.supplyAsync(() -> {
                    try {
                        latch.await(); // ç­‰å¾…å‘ä»¤æªå“
                        MockMultipartFile chunkFile = new MockMultipartFile("chunkFile", "part_1", "application/octet-stream", firstChunkData);

                        UploadChunkReqDTO dto = new UploadChunkReqDTO();
                        dto.setTaskId(taskId);
                        dto.setChunkIndex(finalI); // å›ºå®šä¸Šä¼ ç¬¬1ç‰‡
                        dto.setChunkFile(chunkFile);
                        dto.setChunkHash(chunkHash);
                        dto.setBucketName(bucketName);

                        boolean flag = true;
                        R r = null;
                        while (flag) {
                            Thread.sleep(1000);
                            r = sysChunkFileService.checkChunk(taskId, finalI);
                            if (!(boolean) r.getData()) {
                                r = sysChunkFileService.uploadChunk(dto);
                                if (r.getCode() != 200) {
                                    System.out.println("ç¬¬" + finalI + "ä¸ªåˆ†ç‰‡ä¸Šä¼ è¿”å›failï¼åŸå› ï¼š" + r.getMsg());
                                } else {
                                    flag = false;
                                }
                            } else {
                                flag = false;
                            }
                        }
                        return r;
                    } catch (Exception e) {
                        return R.fail(e.getMessage());
                    }
                }, executor));
            }

            System.out.println("ğŸš€ å‡†å¤‡å°±ç»ªï¼Œ40ä¸ªè¯·æ±‚å¼€å§‹å†²æ’ uploadChunk æ¥å£...");
            latch.countDown();
            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();

            System.out.println("=======================   ç»“æŸ   ==========================");
        }

    }

    @Test
    @DisplayName("é«˜å¹¶å‘åˆå¹¶æµ‹è¯•ï¼šæ¨¡æ‹Ÿåˆ†ç‰‡å®Œæˆåç–¯ç‹‚ç‚¹å‡»åˆå¹¶")
    public void testConcurrentMerge() throws Exception {
        // å‰æï¼šç¡®ä¿åˆ†ç‰‡å·²ç»é€šè¿‡ä¸Šé¢çš„æ–¹æ³•æˆ–å·¥å…·å…¨éƒ¨ä¼ å®Œ
        int threadCount = 10;
        ExecutorService executor = Executors.newFixedThreadPool(threadCount);
        CountDownLatch latch = new CountDownLatch(1);

        List<CompletableFuture<R>> futures = new ArrayList<>();

        for (int i = 0; i < threadCount; i++) {
            futures.add(CompletableFuture.supplyAsync(() -> {
                try {
                    latch.await();
                    return sysChunkFileService.mergeChunk(taskId);
                } catch (Exception e) {
                    return R.fail(e.getMessage());
                }
            }, executor));
        }

        System.out.println("ğŸš€ å‡†å¤‡å°±ç»ªï¼Œ10ä¸ªçº¿ç¨‹åŒæ—¶å‘èµ· mergeChunk è¯·æ±‚...");
        latch.countDown();
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();

        // éªŒè¯åˆ†å¸ƒå¼é”æ˜¯å¦ç”Ÿæ•ˆ
        AtomicInteger mergedSuccess = new AtomicInteger();
        AtomicInteger blockedByLock = new AtomicInteger();

        futures.forEach(f -> {
            R r = f.join();
            if (r.getCode() == 200) mergedSuccess.getAndIncrement();
            else if (r.getMsg().contains("å¤„ç†ä¸­")) blockedByLock.getAndIncrement();
        });

        System.out.println("ğŸ† åˆå¹¶é€»è¾‘è¿›å…¥æ¬¡æ•°ï¼š" + mergedSuccess.get());
        System.out.println("ğŸ”’ è¢«åˆ†å¸ƒå¼é”æ‹¦æˆªæ¬¡æ•°ï¼š" + blockedByLock.get());
    }

    /**
     * å·¥å…·æ–¹æ³•ï¼šä»æŒ‡å®šå¤§æ–‡ä»¶ä¸­è¯»å–åˆ†ç‰‡æ•°æ®
     */
    private byte[] getChunkDataFromFile(String filePath, int index, long chunkSize) throws IOException {
        File file = new File(filePath);
        try (RandomAccessFile raf = new RandomAccessFile(file, "r")) {
            long offset = index * chunkSize;
            raf.seek(offset);
            int length = (int) Math.min(chunkSize, file.length() - offset);
            byte[] b = new byte[length];
            raf.readFully(b);
            return b;
        }
    }
}